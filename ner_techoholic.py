# -*- coding: utf-8 -*-
"""NER_Techoholic.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14EesfJDXLK-Hv-2-qIKr3_zD48vPOHlv
"""

import os
import json
import spacy
# Reading Data from Google Drive
from google.colab import drive
drive.mount('/content/drive/')

pip install pdfminer.six

pip install PyPDF2

from pdfminer.converter import TextConverter
from pdfminer.pdfinterp import PDFPageInterpreter
from pdfminer.pdfinterp import PDFResourceManager
from pdfminer.layout import LAParams
from pdfminer.pdfpage import PDFPage
import io

pip install mammoth

# import mammoth
# def TextFileFromDOCX(path_to_resumedocx_files):
#   for filename in os.listdir(path_to_resumedocx_files):
#     absolute_file_path = os.path.join(path_to_resumedocx_files, filename)
#     with open(absolute_file_path, 'rb') as fh:
#       with open(os.path.splitext(absolute_file_path)[0] + ".txt", encoding="utf-8", mode="a") as f:
#         result = mammoth.extract_raw_text(fh)
#         text = result.value
        
#         f.write(text)

# TextFileFromDOCX('/content/drive/MyDrive/experiment_folder/Hirehunch_docxResume')

#Real
# def TextFileFromPDF(path_to_resumePDF_files, TextFile_Path):
#   for filename in os.listdir(path_to_resumePDF_files):
#     absolute_file_path = os.path.join(path_to_resumePDF_files, filename)
#     with open(absolute_file_path, 'rb') as fh:
#       with open(os.path.splitext(absolute_file_path)[0] + ".txt", encoding="utf-8", mode="a") as f:
#         for page in PDFPage.get_pages(fh,caching=True,check_extractable=True):
#           resource_manager = PDFResourceManager()
#           fake_file_handle = io.StringIO()
#           converter = TextConverter(resource_manager, fake_file_handle, codec='utf-8', laparams=LAParams())
#           page_interpreter = PDFPageInterpreter(resource_manager, converter)
#           page_interpreter.process_page(page)
#           text = fake_file_handle.getvalue()
#           f.write(text)
#         f.close()
#         converter.close()
#         fake_file_handle.close()

# try:
#             with open( filename, "rb") as docx_file:
#                 result = mammoth.extract_raw_text(docx_file)
#                 text = result.value
#                 text = text.title()
#                 fileTXT.append(text)
#         except Exception:
#             logging.warning('Error reading .docx file :')

# TextFileFromPDF("/content/drive/MyDrive/HireHunch_Resumes.zip_Unzipped/Resume", "/content/drive/MyDrive/HireHunch_Resumes.zip_Unzipped/TextFileOF_Resume" )

import json
import spacy
import random

def trainingSpacy():
  training_data = []
  lines=[]
  with open('/content/drive/MyDrive/hirehunchCompleteJSONfILE.json', 'r') as f:
    lines = f.readlines()
  for line in lines:
            data = json.loads(line)
            text = data['annotations']
            flat_list= [] 
            flat_list = [item for sublist in text for item in sublist] # convert list of list into list
            training_data.append((flat_list[0],  flat_list[1]))
  nlp = spacy.blank('en')  # create blank Language class
    # create the built-in pipeline components and add them to the pipeline
    # nlp.create_pipe works for built-ins that are registered with spaCy
  if 'ner' not in nlp.pipe_names:
    ner = nlp.create_pipe('ner')
    nlp.add_pipe(ner, last=True)
  for _, annotations in training_data:
    for ent in annotations.get('entities'):
      ner.add_label(ent[2])
  other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']
  with nlp.disable_pipes(*other_pipes):
    optimizer = nlp.begin_training()
  for itn in range(30):
    print("Statring iteration " + str(itn))
    random.shuffle(training_data) 
    losses = {}
    for text, annotations in training_data:
      nlp.update([text],[annotations],drop=0.2,sgd=optimizer,losses=losses)
      print(losses)

nlp.to_disk('/content/drive/MyDrive/CompleteData_SPACY_hirehunch_CompanyData_NER_weights')



model = spacy.load('/content/drive/MyDrive/CompleteData_SPACY_hirehunch_CompanyData_NER_weights')

def extract_text_from_pdf(pdf_path):
    '''
    Helper function to extract the plain text from .pdf files

    :param pdf_path: path to PDF file to be extracted
    :return: iterator of string of extracted text
    '''
    # https://www.blog.pythonlibrary.org/2018/05/03/exporting-data-from-pdfs-with-python/
    with open(pdf_path, 'rb') as fh:
        for page in PDFPage.get_pages(fh, 
                                      caching=True,
                                      check_extractable=True):
            resource_manager = PDFResourceManager()
            fake_file_handle = io.StringIO()
            converter = TextConverter(resource_manager, fake_file_handle, codec='utf-8', laparams=LAParams())
            page_interpreter = PDFPageInterpreter(resource_manager, converter)
            page_interpreter.process_page(page)
            text = fake_file_handle.getvalue()
            yield text
 
            # close open handles
            converter.close()
            fake_file_handle.close()

import mammoth
def TextFileFromDOCX_single(path_to_resumedocx_files):
    with open(path_to_resumedocx_files, 'rb') as fh:
        result = mammoth.extract_raw_text(fh)
        text = result.value
        text = text.title()
        yield text

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Shivam_Jha.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/Abhiram.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/ajoy-kumar-cv.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/asmit-basu-cv.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/chandranshu-awasthi-cv.doc.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/dhananjay-dubey-cv (1).pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/erankitsh.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/govindarao-kondala-cv.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/Abhishek.docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/amit-tripathi-cv.docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/Anuj_Kumar.docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/Ayeesha_Resume.docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/devendra-kumar-anchal-cv.docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/gagandeep-mishra-cv.docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/GMallikarjunaReddy--EL (1).docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/cv1.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/cv2.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(TextFileFromDOCX_single('/content/drive/MyDrive/Testing_resume_hirehunch/cv3.docx')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/cv4.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

print(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/cv4.pdf')))

check2 =model(''.join(extract_text_from_pdf('/content/drive/MyDrive/Testing_resume_hirehunch/cv5.pdf')))
for ent in check2.ents:
  print(ent.text, '<-', ent.label_)

